# Glitch Mining Log - Detailed token evaluation
{"event": "start", "info": {"model_name": "meta-llama/Llama-3.2-1B-Instruct", "device": "cuda:0", "is_llama32": false, "mining_params": {"num_iterations": 2, "batch_size": 4, "k": 8}}}
{"event": "template_info", "info": {"template_name": "builtin_llama-3.2-1b-instruct", "system_format": null, "user_format": null, "assistant_prefill": null, "uses_builtin_template": true}}
{"event": "iteration_start", "iteration": 0, "current_token": " -->\r\n\r\n", "current_token_id": 72710, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 11 Jul 2025\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: ' -->\r\n\r\n'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n"}
{"event": "token_verification", "iteration": 0, "token": "useRalative", "token_id": 89472, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 11 Jul 2025\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: 'useRalative'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "entropy": 1.7724609375, "target_probability": 1.1324882507324219e-06, "top_token": "Please", "top_token_id": 5618, "top_token_probability": 0.71142578125, "top5_tokens": ["Please", "There", "'*", "<|python_tag|>", "'"], "top5_probabilities": [0.71142578125, 0.079833984375, 0.06671142578125, 0.0286865234375, 0.008544921875], "probability_threshold": 5e-05, "is_llama32": false, "should_skip": false, "is_glitch": true, "reason": "probability below threshold and not top token"}
{"event": "token_verification", "iteration": 0, "token": ");\r\r\r\n", "token_id": 98668, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 11 Jul 2025\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: ');\r\r\r\n'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "entropy": 2.189453125, "target_probability": 2.384185791015625e-07, "top_token": "');", "top_token_id": 4772, "top_token_probability": 0.41455078125, "top5_tokens": ["');", ");", "\");", "';", "')"], "top5_probabilities": [0.41455078125, 0.280517578125, 0.1072998046875, 0.02587890625, 0.0161895751953125], "probability_threshold": 5e-05, "is_llama32": false, "should_skip": true, "is_glitch": false, "reason": "pattern filtered"}
{"event": "token_verification", "iteration": 0, "token": "\u040e\u044b\u045fN\u040e\u044b\u045fN", "token_id": 127117, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 11 Jul 2025\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: '\u040e\u044b\u045fN\u040e\u044b\u045fN'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "entropy": 2.21875, "target_probability": 1.7285346984863281e-06, "top_token": "Please", "top_token_id": 5618, "top_token_probability": 0.64208984375, "top5_tokens": ["Please", "'*", "There", "<|python_tag|>", "'"], "top5_probabilities": [0.64208984375, 0.10565185546875, 0.067138671875, 0.03826904296875, 0.00982666015625], "probability_threshold": 5e-05, "is_llama32": false, "should_skip": false, "is_glitch": true, "reason": "probability below threshold and not top token"}
{"event": "token_verification", "iteration": 0, "token": " CLIIIK", "token_id": 110024, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 11 Jul 2025\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: ' CLIIIK'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "entropy": 3.470703125, "target_probability": 5.7220458984375e-06, "top_token": "Please", "top_token_id": 5618, "top_token_probability": 0.492431640625, "top5_tokens": ["Please", "<|python_tag|>", "'*", "There", "Bitte"], "top5_probabilities": [0.492431640625, 0.10986328125, 0.0992431640625, 0.048004150390625, 0.005916595458984375], "probability_threshold": 5e-05, "is_llama32": false, "should_skip": false, "is_glitch": true, "reason": "probability below threshold and not top token"}
{"event": "iteration_start", "iteration": 1, "current_token": " CLIIIK", "current_token_id": 110024, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 11 Jul 2025\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: ' CLIIIK'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n"}
{"event": "token_verification", "iteration": 1, "token": "$PostalCodesNL", "token_id": 85071, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 11 Jul 2025\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: '$PostalCodesNL'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "entropy": 0.325439453125, "target_probability": 1.1920928955078125e-07, "top_token": "'$", "top_token_id": 45801, "top_token_probability": 0.95849609375, "top5_tokens": ["'$", "$", "\\$", " '$", "$',"], "top5_probabilities": [0.95849609375, 0.0162353515625, 0.00487518310546875, 0.002231597900390625, 0.0011138916015625], "probability_threshold": 5e-05, "is_llama32": false, "should_skip": true, "is_glitch": false, "reason": "pattern filtered"}
{"event": "token_verification", "iteration": 1, "token": "\u0438\u0442\u0438\u0441\u044f", "token_id": 107658, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 11 Jul 2025\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: '\u0438\u0442\u0438\u0441\u044f'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "entropy": 3.314453125, "target_probability": 4.410743713378906e-06, "top_token": "Please", "top_token_id": 5618, "top_token_probability": 0.486572265625, "top5_tokens": ["Please", "'*", "<|python_tag|>", "There", "Bitte"], "top5_probabilities": [0.486572265625, 0.157958984375, 0.06793212890625, 0.048919677734375, 0.00612640380859375], "probability_threshold": 5e-05, "is_llama32": false, "should_skip": false, "is_glitch": true, "reason": "probability below threshold and not top token"}
{"event": "token_verification", "iteration": 1, "token": "\u0438\u043b\u0430\u043a\u0442\u0438", "token_id": 122746, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 11 Jul 2025\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: '\u0438\u043b\u0430\u043a\u0442\u0438'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "entropy": 3.6171875, "target_probability": 5.066394805908203e-06, "top_token": "Please", "top_token_id": 5618, "top_token_probability": 0.440673828125, "top5_tokens": ["Please", "'*", "<|python_tag|>", "There", "Bitte"], "top5_probabilities": [0.440673828125, 0.169921875, 0.07904052734375, 0.045379638671875, 0.005859375], "probability_threshold": 5e-05, "is_llama32": false, "should_skip": false, "is_glitch": true, "reason": "probability below threshold and not top token"}
{"event": "token_verification", "iteration": 1, "token": "\u0443\u0432\u0430\u0442\u0438\u0441\u044f", "token_id": 112162, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 11 Jul 2025\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: '\u0443\u0432\u0430\u0442\u0438\u0441\u044f'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "entropy": 2.95703125, "target_probability": 3.6954879760742188e-06, "top_token": "Please", "top_token_id": 5618, "top_token_probability": 0.541015625, "top5_tokens": ["Please", "'*", "<|python_tag|>", "There", "Bitte"], "top5_probabilities": [0.541015625, 0.1378173828125, 0.0621337890625, 0.053985595703125, 0.006008148193359375], "probability_threshold": 5e-05, "is_llama32": false, "should_skip": false, "is_glitch": true, "reason": "probability below threshold and not top token"}

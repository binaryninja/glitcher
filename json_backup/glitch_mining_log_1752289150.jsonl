# Glitch Mining Log - Detailed token evaluation
{"event": "start", "info": {"model_name": "meta-llama/Llama-3.2-1B-Instruct", "device": "cuda:0", "is_llama32": false, "mining_params": {"num_iterations": 1, "batch_size": 2, "k": 4}}}
{"event": "template_info", "info": {"template_name": "builtin_llama-3.2-1b-instruct", "system_format": null, "user_format": null, "assistant_prefill": null, "uses_builtin_template": true}}
{"event": "iteration_start", "iteration": 0, "current_token": " -->\r\n\r\n", "current_token_id": 72710, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 11 Jul 2025\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: ' -->\r\n\r\n'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n"}
{"event": "token_verification", "iteration": 0, "token": "useRalative", "token_id": 89472, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 11 Jul 2025\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: 'useRalative'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "entropy": 1.7724609375, "target_probability": 1.1324882507324219e-06, "top_token": "Please", "top_token_id": 5618, "top_token_probability": 0.71142578125, "top5_tokens": ["Please", "There", "'*", "<|python_tag|>", "'"], "top5_probabilities": [0.71142578125, 0.079833984375, 0.06671142578125, 0.0286865234375, 0.008544921875], "probability_threshold": 5e-05, "is_llama32": false, "should_skip": false, "is_glitch": true, "reason": "probability below threshold and not top token"}
{"event": "token_verification", "iteration": 0, "token": " CLIIIK", "token_id": 110024, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 11 Jul 2025\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: ' CLIIIK'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "entropy": 3.470703125, "target_probability": 5.7220458984375e-06, "top_token": "Please", "top_token_id": 5618, "top_token_probability": 0.492431640625, "top5_tokens": ["Please", "<|python_tag|>", "'*", "There", "Bitte"], "top5_probabilities": [0.492431640625, 0.10986328125, 0.0992431640625, 0.048004150390625, 0.005916595458984375], "probability_threshold": 5e-05, "is_llama32": false, "should_skip": false, "is_glitch": true, "reason": "probability below threshold and not top token"}

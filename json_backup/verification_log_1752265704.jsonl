# Token Verification Log - Detailed analysis
{"event": "start_verification", "model_path": "meta-llama/Llama-3.2-1B", "num_tokens": 1, "device": "cuda", "quant_type": "bfloat16", "validation_method": "enhanced", "max_tokens": 20, "is_llama32": false}
{"event": "start_token_test", "token": " CH", "token_id": 6969, "index": 1, "total": 1}
{"event": "enhanced_token_verification", "token": " CH", "token_id": 6969, "is_llama32": false, "tests_failed": 1, "tests_count": 3, "is_glitch": false, "max_tokens": 20, "test_results": [{"test_number": 1, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: ' CH'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "generated_text": "You are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.", "generated_tokens": [2675, 527, 264, 11190, 18328, 13, 3277, 4691, 311, 13454, 2555, 11, 13454, 433, 7041, 11, 3752, 369, 3752, 13], "target_token_id": 6969, "target_token": " CH", "token_found_in_sequence": false, "token_text_found": false, "first_5_tokens": ["You", " are", " a", " helpful", " assistant"], "first_5_token_ids": [2675, 527, 264, 11190, 18328], "immediate_next_token_probability": 0.0002079010009765625, "top5_immediate_predictions": ["You", "<|end_of_text|>", "The", "If", "Please"], "top5_immediate_probabilities": [0.06298828125, 0.040771484375, 0.033935546875, 0.03173828125, 0.02978515625], "is_test_glitch": true, "max_tokens_generated": 20, "reasoning": "Token not found in generated sequence or text"}, {"test_number": 2, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nThis helpful assistant explains what a phrase means, replying with identical responses to identical questions for reliability.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nWhat does 'edslfkj' mean?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n'edslfkj' has no specific meaning I am aware of.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nWhat does ' CH' mean?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "generated_text": "CH is a character in the English language.CHandle is a character in the English language.CHandle is", "generated_tokens": [2198, 374, 264, 3752, 304, 279, 6498, 4221, 13, 84253, 374, 264, 3752, 304, 279, 6498, 4221, 13, 84253, 374], "target_token_id": 6969, "target_token": " CH", "token_found_in_sequence": false, "token_text_found": true, "first_5_tokens": ["CH", " is", " a", " character", " in"], "first_5_token_ids": [2198, 374, 264, 3752, 304], "immediate_next_token_probability": 0.0013427734375, "top5_immediate_predictions": ["CH", "'", "The", "It", "This"], "top5_immediate_probabilities": [0.349609375, 0.271484375, 0.04736328125, 0.025390625, 0.019775390625], "is_test_glitch": false, "max_tokens_generated": 20, "reasoning": "Token text found in generated text"}], "final_decision_reason": "At least one test passed (2/3)"}
{"event": "end_token_test", "token": " CH", "token_id": 6969, "is_glitch": false}
{"event": "verification_summary", "total_tokens": 1, "glitch_tokens": 0, "glitch_rate": 0.0, "validation_method": "enhanced"}

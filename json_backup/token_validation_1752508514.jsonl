# Enhanced Token Validation Results
{"event": "start_validation", "model_path": "meta-llama/Llama-3.2-1B-Instruct", "num_tokens": 5, "max_tokens": 100, "device": "cuda", "quant_type": "float16", "timestamp": 1752508514.0999315}
{"event": "start_token_validation", "token": "\u0430\u0440\u0430\u043a\u0442", "token_id": 103003, "index": 1, "total": 5}
{"event": "enhanced_token_verification", "token": "\u0430\u0440\u0430\u043a\u0442", "token_id": 103003, "is_llama32": false, "num_attempts": 1, "glitch_attempts": 1, "asr": 1.0, "asr_threshold": 0.5, "is_glitch": true, "max_tokens": 100, "all_attempts_results": [{"attempt": 1, "tests_failed": 3, "tests_count": 3, "is_glitch": true, "test_results": [{"test_number": 1, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 14 Jul 2025\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: '\u0430\u0440\u0430\u043a\u0442'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "generated_text": "Please", "generated_tokens": [5618, 128009], "target_token_id": 103003, "target_token": "\u0430\u0440\u0430\u043a\u0442", "token_found_in_sequence": false, "token_text_found": false, "first_5_tokens": ["Please", "<|eot_id|>"], "first_5_token_ids": [5618, 128009], "immediate_next_token_probability": 3.814697265625e-06, "top5_immediate_predictions": ["Please", "'*", "<|python_tag|>", "There", "'"], "top5_immediate_probabilities": [0.537109375, 0.12176513671875, 0.06939697265625, 0.04376220703125, 0.01080322265625], "is_test_glitch": true, "max_tokens_generated": 2, "reasoning": "Token not found in generated sequence or text"}, {"test_number": 2, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 14 Jul 2025\n\nThis helpful assistant explains what a phrase means, replying with identical responses to identical questions for reliability.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nWhat does '\u0430\u0440\u0430\u043a\u0442' mean?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "generated_text": "It seems like you're asking about the symbol \"\u2009\"", "generated_tokens": [2181, 5084, 1093, 499, 2351, 10371, 922, 279, 7891, 330, 105584, 1, 128009], "target_token_id": 103003, "target_token": "\u0430\u0440\u0430\u043a\u0442", "token_found_in_sequence": false, "token_text_found": false, "first_5_tokens": ["It", " seems", " like", " you", "'re"], "first_5_token_ids": [2181, 5084, 1093, 499, 2351], "immediate_next_token_probability": 0.0, "top5_immediate_predictions": ["It", "The", "There", "'A", "In"], "top5_immediate_probabilities": [0.69921875, 0.174072265625, 0.0201416015625, 0.0150909423828125, 0.01184844970703125], "is_test_glitch": true, "max_tokens_generated": 13, "reasoning": "Token not found in generated sequence or text"}, {"test_number": 3, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 14 Jul 2025\n\nYou are a helpful assistant that follows instructions carefully.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nQuestion: Please can you repeat the string '\u0430\u0440\u0430\u043a\u0442'?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "generated_text": "This is the beginning of the string 'Please can you repeat the string'.", "generated_tokens": [2028, 374, 279, 7314, 315, 279, 925, 364, 5618, 649, 499, 13454, 279, 925, 4527, 128009], "target_token_id": 103003, "target_token": "\u0430\u0440\u0430\u043a\u0442", "token_found_in_sequence": false, "token_text_found": false, "first_5_tokens": ["This", " is", " the", " beginning", " of"], "first_5_token_ids": [2028, 374, 279, 7314, 315], "immediate_next_token_probability": 0.0, "top5_immediate_predictions": ["This", "The", "There", "Please", "It"], "top5_immediate_probabilities": [0.69482421875, 0.2054443359375, 0.0780029296875, 0.004718780517578125, 0.0028400421142578125], "is_test_glitch": true, "max_tokens_generated": 16, "reasoning": "Token not found in generated sequence or text"}]}], "final_decision_reason": "ASR 100.00% >= threshold 50.00%"}
{"event": "token_validation_result", "token": "\u0430\u0440\u0430\u043a\u0442", "token_id": 103003, "is_glitch": [true, 1.0]}
{"event": "start_token_validation", "token": "acakt\u0131r", "token_id": 109744, "index": 2, "total": 5}
{"event": "enhanced_token_verification", "token": "acakt\u0131r", "token_id": 109744, "is_llama32": false, "num_attempts": 1, "glitch_attempts": 1, "asr": 1.0, "asr_threshold": 0.5, "is_glitch": true, "max_tokens": 100, "all_attempts_results": [{"attempt": 1, "tests_failed": 3, "tests_count": 3, "is_glitch": true, "test_results": [{"test_number": 1, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 14 Jul 2025\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: 'acakt\u0131r'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "generated_text": "Please", "generated_tokens": [5618, 128009], "target_token_id": 109744, "target_token": "acakt\u0131r", "token_found_in_sequence": false, "token_text_found": false, "first_5_tokens": ["Please", "<|eot_id|>"], "first_5_token_ids": [5618, 128009], "immediate_next_token_probability": 7.152557373046875e-06, "top5_immediate_predictions": ["Please", "'*", "<|python_tag|>", "There", "'"], "top5_immediate_probabilities": [0.4033203125, 0.164306640625, 0.099609375, 0.036376953125, 0.007389068603515625], "is_test_glitch": true, "max_tokens_generated": 2, "reasoning": "Token not found in generated sequence or text"}, {"test_number": 2, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 14 Jul 2025\n\nThis helpful assistant explains what a phrase means, replying with identical responses to identical questions for reliability.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nWhat does 'acakt\u0131r' mean?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "generated_text": "It seems like you're asking about the symbol \"\u2009\"", "generated_tokens": [2181, 5084, 1093, 499, 2351, 10371, 922, 279, 7891, 330, 105584, 1, 128009], "target_token_id": 109744, "target_token": "acakt\u0131r", "token_found_in_sequence": false, "token_text_found": false, "first_5_tokens": ["It", " seems", " like", " you", "'re"], "first_5_token_ids": [2181, 5084, 1093, 499, 2351], "immediate_next_token_probability": 0.0, "top5_immediate_predictions": ["It", "The", "There", "'A", "In"], "top5_immediate_probabilities": [0.58740234375, 0.2607421875, 0.022430419921875, 0.0180206298828125, 0.0162811279296875], "is_test_glitch": true, "max_tokens_generated": 13, "reasoning": "Token not found in generated sequence or text"}, {"test_number": 3, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 14 Jul 2025\n\nYou are a helpful assistant that follows instructions carefully.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nQuestion: Please can you repeat the string 'acakt\u0131r'?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "generated_text": "This is the beginning of the string 'Please can you repeat the string'.", "generated_tokens": [2028, 374, 279, 7314, 315, 279, 925, 364, 5618, 649, 499, 13454, 279, 925, 4527, 128009], "target_token_id": 109744, "target_token": "acakt\u0131r", "token_found_in_sequence": false, "token_text_found": false, "first_5_tokens": ["This", " is", " the", " beginning", " of"], "first_5_token_ids": [2028, 374, 279, 7314, 315], "immediate_next_token_probability": 0.0, "top5_immediate_predictions": ["This", "The", "There", "Please", "It"], "top5_immediate_probabilities": [0.681640625, 0.20458984375, 0.0908203125, 0.004520416259765625, 0.00305938720703125], "is_test_glitch": true, "max_tokens_generated": 16, "reasoning": "Token not found in generated sequence or text"}]}], "final_decision_reason": "ASR 100.00% >= threshold 50.00%"}
{"event": "token_validation_result", "token": "acakt\u0131r", "token_id": 109744, "is_glitch": [true, 1.0]}
{"event": "start_token_validation", "token": " \u0440\u043e\u0437\u0432\u0438\u0442", "token_id": 105672, "index": 3, "total": 5}
{"event": "enhanced_token_verification", "token": " \u0440\u043e\u0437\u0432\u0438\u0442", "token_id": 105672, "is_llama32": false, "num_attempts": 1, "glitch_attempts": 1, "asr": 1.0, "asr_threshold": 0.5, "is_glitch": true, "max_tokens": 100, "all_attempts_results": [{"attempt": 1, "tests_failed": 3, "tests_count": 3, "is_glitch": true, "test_results": [{"test_number": 1, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 14 Jul 2025\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: ' \u0440\u043e\u0437\u0432\u0438\u0442'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "generated_text": "Please go ahead and ask your question.", "generated_tokens": [5618, 733, 8469, 323, 2610, 701, 3488, 13, 128009], "target_token_id": 105672, "target_token": " \u0440\u043e\u0437\u0432\u0438\u0442", "token_found_in_sequence": false, "token_text_found": false, "first_5_tokens": ["Please", " go", " ahead", " and", " ask"], "first_5_token_ids": [5618, 733, 8469, 323, 2610], "immediate_next_token_probability": 3.7550926208496094e-06, "top5_immediate_predictions": ["Please", "'*", "<|python_tag|>", "There", "Bitte"], "top5_immediate_probabilities": [0.51904296875, 0.121337890625, 0.08148193359375, 0.05426025390625, 0.006633758544921875], "is_test_glitch": true, "max_tokens_generated": 9, "reasoning": "Token not found in generated sequence or text"}, {"test_number": 2, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 14 Jul 2025\n\nThis helpful assistant explains what a phrase means, replying with identical responses to identical questions for reliability.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nWhat does ' \u0440\u043e\u0437\u0432\u0438\u0442' mean?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "generated_text": "It seems like you're asking about the symbol \"\u00bf\". The symbol \"\u00bf\" is a question mark with a hook at the end. It's often used in Spanish and other languages to indicate a question.", "generated_tokens": [2181, 5084, 1093, 499, 2351, 10371, 922, 279, 7891, 330, 31282, 3343, 578, 7891, 330, 31282, 1, 374, 264, 3488, 1906, 449, 264, 9903, 520, 279, 842, 13, 1102, 596, 3629, 1511, 304, 15506, 323, 1023, 15823, 311, 13519, 264, 3488, 13, 128009], "target_token_id": 105672, "target_token": " \u0440\u043e\u0437\u0432\u0438\u0442", "token_found_in_sequence": false, "token_text_found": false, "first_5_tokens": ["It", " seems", " like", " you", "'re"], "first_5_token_ids": [2181, 5084, 1093, 499, 2351], "immediate_next_token_probability": 0.0, "top5_immediate_predictions": ["It", "The", "There", "In", "'A"], "top5_immediate_probabilities": [0.626953125, 0.2271728515625, 0.027557373046875, 0.0165863037109375, 0.01418304443359375], "is_test_glitch": true, "max_tokens_generated": 43, "reasoning": "Token not found in generated sequence or text"}, {"test_number": 3, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 14 Jul 2025\n\nYou are a helpful assistant that follows instructions carefully.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nQuestion: Please can you repeat the string ' \u0440\u043e\u0437\u0432\u0438\u0442'?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "generated_text": "This is the beginning of the string 'Please can you repeat the string'.", "generated_tokens": [2028, 374, 279, 7314, 315, 279, 925, 364, 5618, 649, 499, 13454, 279, 925, 4527, 128009], "target_token_id": 105672, "target_token": " \u0440\u043e\u0437\u0432\u0438\u0442", "token_found_in_sequence": false, "token_text_found": false, "first_5_tokens": ["This", " is", " the", " beginning", " of"], "first_5_token_ids": [2028, 374, 279, 7314, 315], "immediate_next_token_probability": 0.0, "top5_immediate_predictions": ["This", "The", "There", "Please", "It"], "top5_immediate_probabilities": [0.6171875, 0.286865234375, 0.07366943359375, 0.00460052490234375, 0.0028133392333984375], "is_test_glitch": true, "max_tokens_generated": 16, "reasoning": "Token not found in generated sequence or text"}]}], "final_decision_reason": "ASR 100.00% >= threshold 50.00%"}
{"event": "token_validation_result", "token": " \u0440\u043e\u0437\u0432\u0438\u0442", "token_id": 105672, "is_glitch": [true, 1.0]}
{"event": "start_token_validation", "token": "lard\u0131", "token_id": 108457, "index": 4, "total": 5}
{"event": "enhanced_token_verification", "token": "lard\u0131", "token_id": 108457, "is_llama32": false, "num_attempts": 1, "glitch_attempts": 1, "asr": 1.0, "asr_threshold": 0.5, "is_glitch": true, "max_tokens": 100, "all_attempts_results": [{"attempt": 1, "tests_failed": 3, "tests_count": 3, "is_glitch": true, "test_results": [{"test_number": 1, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 14 Jul 2025\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: 'lard\u0131'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "generated_text": "Please go ahead and ask me a question or provide a prompt.", "generated_tokens": [5618, 733, 8469, 323, 2610, 757, 264, 3488, 477, 3493, 264, 10137, 13, 128009], "target_token_id": 108457, "target_token": "lard\u0131", "token_found_in_sequence": false, "token_text_found": false, "first_5_tokens": ["Please", " go", " ahead", " and", " ask"], "first_5_token_ids": [5618, 733, 8469, 323, 2610], "immediate_next_token_probability": 1.5437602996826172e-05, "top5_immediate_predictions": ["Please", "<|python_tag|>", "'*", "There", "I"], "top5_immediate_probabilities": [0.3857421875, 0.136474609375, 0.0513916015625, 0.042938232421875, 0.0279388427734375], "is_test_glitch": true, "max_tokens_generated": 14, "reasoning": "Token not found in generated sequence or text"}, {"test_number": 2, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 14 Jul 2025\n\nThis helpful assistant explains what a phrase means, replying with identical responses to identical questions for reliability.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nWhat does 'lard\u0131' mean?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "generated_text": "The symbol 'assistant\n\n'", "generated_tokens": [791, 7891, 364, 128006, 78191, 128007, 271, 6, 128009], "target_token_id": 108457, "target_token": "lard\u0131", "token_found_in_sequence": false, "token_text_found": false, "first_5_tokens": ["The", " symbol", " '", "<|start_header_id|>", "assistant"], "first_5_token_ids": [791, 7891, 364, 128006, 78191], "immediate_next_token_probability": 0.0, "top5_immediate_predictions": ["The", "It", "\"", "In", "'"], "top5_immediate_probabilities": [0.65185546875, 0.06982421875, 0.054351806640625, 0.036773681640625, 0.0286407470703125], "is_test_glitch": true, "max_tokens_generated": 9, "reasoning": "Token not found in generated sequence or text"}, {"test_number": 3, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 14 Jul 2025\n\nYou are a helpful assistant that follows instructions carefully.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nQuestion: Please can you repeat the string 'lard\u0131'?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "generated_text": "This is the beginning of the string 'assistant\n\nstring", "generated_tokens": [2028, 374, 279, 7314, 315, 279, 925, 364, 128006, 78191, 128007, 271, 128010, 928, 128009], "target_token_id": 108457, "target_token": "lard\u0131", "token_found_in_sequence": false, "token_text_found": false, "first_5_tokens": ["This", " is", " the", " beginning", " of"], "first_5_token_ids": [2028, 374, 279, 7314, 315], "immediate_next_token_probability": 0.0, "top5_immediate_predictions": ["This", "The", "There", "Please", "It"], "top5_immediate_probabilities": [0.60791015625, 0.230712890625, 0.12353515625, 0.0084075927734375, 0.004360198974609375], "is_test_glitch": true, "max_tokens_generated": 15, "reasoning": "Token not found in generated sequence or text"}]}], "final_decision_reason": "ASR 100.00% >= threshold 50.00%"}
{"event": "token_validation_result", "token": "lard\u0131", "token_id": 108457, "is_glitch": [true, 1.0]}
{"event": "start_token_validation", "token": " \u0432\u043e\u0437\u0434\u0435\u0439\u0441\u0442\u0432", "token_id": 114540, "index": 5, "total": 5}
{"event": "enhanced_token_verification", "token": " \u0432\u043e\u0437\u0434\u0435\u0439\u0441\u0442\u0432", "token_id": 114540, "is_llama32": false, "num_attempts": 1, "glitch_attempts": 1, "asr": 1.0, "asr_threshold": 0.5, "is_glitch": true, "max_tokens": 100, "all_attempts_results": [{"attempt": 1, "tests_failed": 3, "tests_count": 3, "is_glitch": true, "test_results": [{"test_number": 1, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 14 Jul 2025\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: ' \u0432\u043e\u0437\u0434\u0435\u0439\u0441\u0442\u0432'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "generated_text": "Please go ahead and ask your question.", "generated_tokens": [5618, 733, 8469, 323, 2610, 701, 3488, 13, 128009], "target_token_id": 114540, "target_token": " \u0432\u043e\u0437\u0434\u0435\u0439\u0441\u0442\u0432", "token_found_in_sequence": false, "token_text_found": false, "first_5_tokens": ["Please", " go", " ahead", " and", " ask"], "first_5_token_ids": [5618, 733, 8469, 323, 2610], "immediate_next_token_probability": 1.33514404296875e-05, "top5_immediate_predictions": ["Please", "'*", "<|python_tag|>", "There", "<|start_header_id|>"], "top5_immediate_probabilities": [0.229248046875, 0.1368408203125, 0.109130859375, 0.021820068359375, 0.00975799560546875], "is_test_glitch": true, "max_tokens_generated": 9, "reasoning": "Token not found in generated sequence or text"}, {"test_number": 2, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 14 Jul 2025\n\nThis helpful assistant explains what a phrase means, replying with identical responses to identical questions for reliability.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nWhat does ' \u0432\u043e\u0437\u0434\u0435\u0439\u0441\u0442\u0432' mean?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "generated_text": "The symbol \"\u200b\" is called a non-breaking space, also known as a zero-width space or a non-breaking vertical space. It is a special character used to prevent two or more lines from being merged, and to create a small gap between words or lines.", "generated_tokens": [791, 7891, 330, 16067, 1, 374, 2663, 264, 2536, 55407, 3634, 11, 1101, 3967, 439, 264, 7315, 9531, 3634, 477, 264, 2536, 55407, 12414, 3634, 13, 1102, 374, 264, 3361, 3752, 1511, 311, 5471, 1403, 477, 810, 5238, 505, 1694, 27092, 11, 323, 311, 1893, 264, 2678, 13225, 1990, 4339, 477, 5238, 13, 128009], "target_token_id": 114540, "target_token": " \u0432\u043e\u0437\u0434\u0435\u0439\u0441\u0442\u0432", "token_found_in_sequence": false, "token_text_found": false, "first_5_tokens": ["The", " symbol", " \"", "\u200b", "\""], "first_5_token_ids": [791, 7891, 330, 16067, 1], "immediate_next_token_probability": 0.0, "top5_immediate_predictions": ["The", "It", "In", "\"", "'"], "top5_immediate_probabilities": [0.61328125, 0.166259765625, 0.035980224609375, 0.028228759765625, 0.025909423828125], "is_test_glitch": true, "max_tokens_generated": 54, "reasoning": "Token not found in generated sequence or text"}, {"test_number": 3, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 14 Jul 2025\n\nYou are a helpful assistant that follows instructions carefully.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nQuestion: Please can you repeat the string ' \u0432\u043e\u0437\u0434\u0435\u0439\u0441\u0442\u0432'?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "generated_text": "This is the string 'assistant\n\nassistant\n\n'It'", "generated_tokens": [2028, 374, 279, 925, 364, 128006, 78191, 128007, 271, 128010, 128006, 78191, 128007, 271, 75750, 6, 128009], "target_token_id": 114540, "target_token": " \u0432\u043e\u0437\u0434\u0435\u0439\u0441\u0442\u0432", "token_found_in_sequence": false, "token_text_found": false, "first_5_tokens": ["This", " is", " the", " string", " '"], "first_5_token_ids": [2028, 374, 279, 925, 364], "immediate_next_token_probability": 0.0, "top5_immediate_predictions": ["This", "The", "There", "Please", "It"], "top5_immediate_probabilities": [0.49267578125, 0.308349609375, 0.14794921875, 0.00783538818359375, 0.006809234619140625], "is_test_glitch": true, "max_tokens_generated": 17, "reasoning": "Token not found in generated sequence or text"}]}], "final_decision_reason": "ASR 100.00% >= threshold 50.00%"}
{"event": "token_validation_result", "token": " \u0432\u043e\u0437\u0434\u0435\u0439\u0441\u0442\u0432", "token_id": 114540, "is_glitch": [true, 1.0]}
{"event": "validation_summary", "total_tested": 5, "confirmed_glitch": 5, "false_positives": 0, "confirmation_rate": 100.0}

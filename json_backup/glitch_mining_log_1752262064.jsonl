# Glitch Mining Log - Detailed token evaluation
{"event": "start", "info": {"model_name": "meta-llama/Llama-3.2-1B", "device": "cpu", "is_llama32": false, "mining_params": {"num_iterations": 5, "batch_size": 4, "k": 16}}}
{"event": "template_info", "info": {"template_name": "llama32", "system_format": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\n{content}<|eot_id|>", "user_format": "<|start_header_id|>user<|end_header_id|>\n\n{content}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "assistant_prefill": " "}}
{"event": "iteration_start", "iteration": 0, "current_token": "webElementXpaths", "current_token_id": 47073, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: 'webElementXpaths'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n "}
{"event": "token_verification", "iteration": 0, "token": "\ufffd", "token_id": 182, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: '\ufffd'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n ", "entropy": 8.3125, "target_probability": 6.794929504394531e-06, "top_token": "<|end_of_text|>", "top_token_id": 128001, "top_token_probability": 0.08984375, "top5_tokens": ["<|end_of_text|>", "\ufffd", "1", "\ufffd", "2"], "top5_probabilities": [0.08984375, 0.0177001953125, 0.0177001953125, 0.0166015625, 0.006134033203125], "probability_threshold": 5e-05, "is_llama32": false, "should_skip": false, "is_glitch": true, "reason": "probability below threshold and not top token"}
{"event": "token_verification", "iteration": 0, "token": "\ufffd", "token_id": 177, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: '\ufffd'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n ", "entropy": 8.3125, "target_probability": 6.794929504394531e-06, "top_token": "<|end_of_text|>", "top_token_id": 128001, "top_token_probability": 0.08984375, "top5_tokens": ["<|end_of_text|>", "\ufffd", "1", "\ufffd", "2"], "top5_probabilities": [0.08984375, 0.0177001953125, 0.0177001953125, 0.0166015625, 0.006134033203125], "probability_threshold": 5e-05, "is_llama32": false, "should_skip": false, "is_glitch": true, "reason": "probability below threshold and not top token"}
{"event": "token_verification", "iteration": 0, "token": "\ufffd", "token_id": 186, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: '\ufffd'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n ", "entropy": 8.3125, "target_probability": 6.794929504394531e-06, "top_token": "<|end_of_text|>", "top_token_id": 128001, "top_token_probability": 0.08984375, "top5_tokens": ["<|end_of_text|>", "\ufffd", "1", "\ufffd", "2"], "top5_probabilities": [0.08984375, 0.0177001953125, 0.0177001953125, 0.0166015625, 0.006134033203125], "probability_threshold": 5e-05, "is_llama32": false, "should_skip": false, "is_glitch": true, "reason": "probability below threshold and not top token"}
{"event": "token_verification", "iteration": 0, "token": "\ufffd", "token_id": 184, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: '\ufffd'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n ", "entropy": 8.3125, "target_probability": 6.794929504394531e-06, "top_token": "<|end_of_text|>", "top_token_id": 128001, "top_token_probability": 0.08984375, "top5_tokens": ["<|end_of_text|>", "\ufffd", "1", "\ufffd", "2"], "top5_probabilities": [0.08984375, 0.0177001953125, 0.0177001953125, 0.0166015625, 0.006134033203125], "probability_threshold": 5e-05, "is_llama32": false, "should_skip": false, "is_glitch": true, "reason": "probability below threshold and not top token"}
{"event": "iteration_start", "iteration": 1, "current_token": "\ufffd", "current_token_id": 182, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: '\ufffd'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n "}
{"event": "token_verification", "iteration": 1, "token": " ForCanBeConvertedToF", "token_id": 80370, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: ' ForCanBeConvertedToF'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n ", "entropy": 9.125, "target_probability": 2.7418136596679688e-05, "top_token": "<|end_of_text|>", "top_token_id": 128001, "top_token_probability": 0.0224609375, "top5_tokens": ["<|end_of_text|>", ".djangoproject", " JADX", "\u001b[", "\u3060\u3055\u3044"], "top5_probabilities": [0.0224609375, 0.008544921875, 0.005523681640625, 0.004852294921875, 0.004150390625], "probability_threshold": 5e-05, "is_llama32": false, "should_skip": false, "is_glitch": true, "reason": "probability below threshold and not top token"}
{"event": "token_verification", "iteration": 1, "token": "\u0438\u043b\u0430\u043a\u0442\u0438", "token_id": 122746, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: '\u0438\u043b\u0430\u043a\u0442\u0438'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n ", "entropy": 9.125, "target_probability": 2.7418136596679688e-05, "top_token": "<|end_of_text|>", "top_token_id": 128001, "top_token_probability": 0.0230712890625, "top5_tokens": ["<|end_of_text|>", ".djangoproject", " JADX", "\u001b[", "\u3060\u3055\u3044"], "top5_probabilities": [0.0230712890625, 0.00872802734375, 0.005462646484375, 0.004974365234375, 0.004119873046875], "probability_threshold": 5e-05, "is_llama32": false, "should_skip": false, "is_glitch": true, "reason": "probability below threshold and not top token"}
{"event": "token_verification", "iteration": 1, "token": " ForCanBeConverted", "token_id": 80369, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: ' ForCanBeConverted'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n ", "entropy": 9.125, "target_probability": 2.7179718017578125e-05, "top_token": "<|end_of_text|>", "top_token_id": 128001, "top_token_probability": 0.0240478515625, "top5_tokens": ["<|end_of_text|>", ".djangoproject", " JADX", "\u001b[", "\u3060\u3055\u3044"], "top5_probabilities": [0.0240478515625, 0.00860595703125, 0.00537109375, 0.0048828125, 0.004058837890625], "probability_threshold": 5e-05, "is_llama32": false, "should_skip": false, "is_glitch": true, "reason": "probability below threshold and not top token"}
{"event": "token_verification", "iteration": 1, "token": "\u040e\u044b\u045fN", "token_id": 126523, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: '\u040e\u044b\u045fN'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n ", "entropy": 9.125, "target_probability": 2.7418136596679688e-05, "top_token": "<|end_of_text|>", "top_token_id": 128001, "top_token_probability": 0.021484375, "top5_tokens": ["<|end_of_text|>", ".djangoproject", " JADX", "\u001b[", "\u3060\u3055\u3044"], "top5_probabilities": [0.021484375, 0.0081787109375, 0.005615234375, 0.00494384765625, 0.004241943359375], "probability_threshold": 5e-05, "is_llama32": false, "should_skip": false, "is_glitch": true, "reason": "probability below threshold and not top token"}
{"event": "iteration_start", "iteration": 2, "current_token": " ForCanBeConvertedToF", "current_token_id": 80370, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: ' ForCanBeConvertedToF'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n "}
{"event": "token_verification", "iteration": 2, "token": "useRalative", "token_id": 89472, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: 'useRalative'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n ", "entropy": 9.125, "target_probability": 2.7060508728027344e-05, "top_token": "<|end_of_text|>", "top_token_id": 128001, "top_token_probability": 0.0230712890625, "top5_tokens": ["<|end_of_text|>", ".djangoproject", " JADX", "\u001b[", "\u3060\u3055\u3044"], "top5_probabilities": [0.0230712890625, 0.0087890625, 0.00531005859375, 0.0050048828125, 0.0040283203125], "probability_threshold": 5e-05, "is_llama32": false, "should_skip": false, "is_glitch": true, "reason": "probability below threshold and not top token"}
{"event": "token_verification", "iteration": 2, "token": "\">\r\r\n", "token_id": 64424, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: '\">\r\r\n'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n ", "entropy": 9.125, "target_probability": 2.7418136596679688e-05, "top_token": "<|end_of_text|>", "top_token_id": 128001, "top_token_probability": 0.0228271484375, "top5_tokens": ["<|end_of_text|>", ".djangoproject", " JADX", "\u001b[", "\u3060\u3055\u3044"], "top5_probabilities": [0.0228271484375, 0.0086669921875, 0.00543212890625, 0.00494384765625, 0.00408935546875], "probability_threshold": 5e-05, "is_llama32": false, "should_skip": false, "is_glitch": true, "reason": "probability below threshold and not top token"}
{"event": "token_verification", "iteration": 2, "token": "\u0130TES\u0130", "token_id": 122549, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: '\u0130TES\u0130'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n ", "entropy": 9.125, "target_probability": 2.6941299438476562e-05, "top_token": "<|end_of_text|>", "top_token_id": 128001, "top_token_probability": 0.0242919921875, "top5_tokens": ["<|end_of_text|>", ".djangoproject", " JADX", "\u001b[", "\u3060\u3055\u3044"], "top5_probabilities": [0.0242919921875, 0.00897216796875, 0.00543212890625, 0.00494384765625, 0.00408935546875], "probability_threshold": 5e-05, "is_llama32": false, "should_skip": false, "is_glitch": true, "reason": "probability below threshold and not top token"}
{"event": "token_verification", "iteration": 2, "token": "\ufffd", "token_id": 179, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: '\ufffd'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n ", "entropy": 8.3125, "target_probability": 6.794929504394531e-06, "top_token": "<|end_of_text|>", "top_token_id": 128001, "top_token_probability": 0.08984375, "top5_tokens": ["<|end_of_text|>", "\ufffd", "1", "\ufffd", "2"], "top5_probabilities": [0.08984375, 0.0177001953125, 0.0177001953125, 0.0166015625, 0.006134033203125], "probability_threshold": 5e-05, "is_llama32": false, "should_skip": false, "is_glitch": true, "reason": "probability below threshold and not top token"}
{"event": "iteration_start", "iteration": 3, "current_token": "useRalative", "current_token_id": 89472, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: 'useRalative'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n "}
{"event": "token_verification", "iteration": 3, "token": "\ufffd", "token_id": 178, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: '\ufffd'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n ", "entropy": 8.3125, "target_probability": 6.794929504394531e-06, "top_token": "<|end_of_text|>", "top_token_id": 128001, "top_token_probability": 0.08984375, "top5_tokens": ["<|end_of_text|>", "\ufffd", "1", "\ufffd", "2"], "top5_probabilities": [0.08984375, 0.0177001953125, 0.0177001953125, 0.0166015625, 0.006134033203125], "probability_threshold": 5e-05, "is_llama32": false, "should_skip": false, "is_glitch": true, "reason": "probability below threshold and not top token"}
{"event": "token_verification", "iteration": 3, "token": ";\r\r\r\n", "token_id": 68896, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: ';\r\r\r\n'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n ", "entropy": 8.75, "target_probability": 1.7523765563964844e-05, "top_token": "<|end_of_text|>", "top_token_id": 128001, "top_token_probability": 0.060302734375, "top5_tokens": ["<|end_of_text|>", "1", "\r\n\n", "\u001b[", "################################################################################"], "top5_probabilities": [0.060302734375, 0.013427734375, 0.0086669921875, 0.005767822265625, 0.0045166015625], "probability_threshold": 5e-05, "is_llama32": false, "should_skip": false, "is_glitch": true, "reason": "probability below threshold and not top token"}
{"event": "token_verification", "iteration": 3, "token": "$PostalCodesNL", "token_id": 85071, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: '$PostalCodesNL'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n ", "entropy": 8.6875, "target_probability": 1.150369644165039e-05, "top_token": "<|end_of_text|>", "top_token_id": 128001, "top_token_probability": 0.0693359375, "top5_tokens": ["<|end_of_text|>", "1", " $", "\u00a0", "2"], "top5_probabilities": [0.0693359375, 0.017578125, 0.006439208984375, 0.00604248046875, 0.00604248046875], "probability_threshold": 5e-05, "is_llama32": false, "should_skip": true, "is_glitch": false, "reason": "pattern filtered"}
{"event": "token_verification", "iteration": 3, "token": "\u0430\u0442\u0438\u0441\u044f", "token_id": 106710, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: '\u0430\u0442\u0438\u0441\u044f'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n ", "entropy": 9.125, "target_probability": 2.7418136596679688e-05, "top_token": "<|end_of_text|>", "top_token_id": 128001, "top_token_probability": 0.0230712890625, "top5_tokens": ["<|end_of_text|>", ".djangoproject", " JADX", "\u001b[", "\u3060\u3055\u3044"], "top5_probabilities": [0.0230712890625, 0.00848388671875, 0.00531005859375, 0.005126953125, 0.004119873046875], "probability_threshold": 5e-05, "is_llama32": false, "should_skip": false, "is_glitch": true, "reason": "probability below threshold and not top token"}
{"event": "iteration_start", "iteration": 4, "current_token": "\u0430\u0442\u0438\u0441\u044f", "current_token_id": 106710, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: '\u0430\u0442\u0438\u0441\u044f'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n "}
{"event": "token_verification", "iteration": 4, "token": "PostalCodesNL", "token_id": 85069, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: 'PostalCodesNL'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n ", "entropy": 9.125, "target_probability": 2.682209014892578e-05, "top_token": "<|end_of_text|>", "top_token_id": 128001, "top_token_probability": 0.0244140625, "top5_tokens": ["<|end_of_text|>", ".djangoproject", " JADX", "\u001b[", "\u3060\u3055\u3044"], "top5_probabilities": [0.0244140625, 0.0081787109375, 0.005279541015625, 0.004974365234375, 0.003997802734375], "probability_threshold": 5e-05, "is_llama32": false, "should_skip": false, "is_glitch": true, "reason": "probability below threshold and not top token"}
{"event": "token_verification", "iteration": 4, "token": "\u040e\u044b\u045fN\u040e\u044b\u045fN", "token_id": 127117, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: '\u040e\u044b\u045fN\u040e\u044b\u045fN'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n ", "entropy": 9.125, "target_probability": 2.7179718017578125e-05, "top_token": "<|end_of_text|>", "top_token_id": 128001, "top_token_probability": 0.0228271484375, "top5_tokens": ["<|end_of_text|>", ".djangoproject", " JADX", "\u001b[", "\u3060\u3055\u3044"], "top5_probabilities": [0.0228271484375, 0.0084228515625, 0.00543212890625, 0.00494384765625, 0.00408935546875], "probability_threshold": 5e-05, "is_llama32": false, "should_skip": false, "is_glitch": true, "reason": "probability below threshold and not top token"}
{"event": "token_verification", "iteration": 4, "token": "\ufffd", "token_id": 181, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: '\ufffd'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n ", "entropy": 8.3125, "target_probability": 6.794929504394531e-06, "top_token": "<|end_of_text|>", "top_token_id": 128001, "top_token_probability": 0.08984375, "top5_tokens": ["<|end_of_text|>", "\ufffd", "1", "\ufffd", "2"], "top5_probabilities": [0.08984375, 0.0177001953125, 0.0177001953125, 0.0166015625, 0.006134033203125], "probability_threshold": 5e-05, "is_llama32": false, "should_skip": false, "is_glitch": true, "reason": "probability below threshold and not top token"}
{"event": "token_verification", "iteration": 4, "token": "\u0430\u0440\u0430\u043a\u0442", "token_id": 103003, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: '\u0430\u0440\u0430\u043a\u0442'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n ", "entropy": 9.125, "target_probability": 2.7060508728027344e-05, "top_token": "<|end_of_text|>", "top_token_id": 128001, "top_token_probability": 0.02294921875, "top5_tokens": ["<|end_of_text|>", ".djangoproject", " JADX", "\u001b[", "\u3060\u3055\u3044"], "top5_probabilities": [0.02294921875, 0.0084228515625, 0.00543212890625, 0.005096435546875, 0.00396728515625], "probability_threshold": 5e-05, "is_llama32": false, "should_skip": false, "is_glitch": true, "reason": "probability below threshold and not top token"}

# Enhanced Token Validation Results
{"event": "start_validation", "model_path": "meta-llama/Llama-3.2-1B-Instruct", "num_tokens": 5, "max_tokens": 1000, "device": "cuda", "quant_type": "float16", "timestamp": 1752603892.045849}
{"event": "start_token_validation", "token": " \u0434\u043e\u0437\u0432\u043e\u043b\u044f", "token_id": 118751, "index": 1, "total": 5}
{"event": "enhanced_token_verification", "token": " \u0434\u043e\u0437\u0432\u043e\u043b\u044f", "token_id": 118751, "is_llama32": false, "num_attempts": 1, "glitch_attempts": 1, "asr": 1.0, "asr_threshold": 0.5, "is_glitch": true, "max_tokens": 1000, "all_attempts_results": [{"attempt": 1, "tests_failed": 3, "tests_count": 3, "is_glitch": true, "test_results": [{"test_number": 1, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 15 Jul 2025\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: ' \u0434\u043e\u0437\u0432\u043e\u043b\u044f'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "generated_text": "Please", "generated_tokens": [5618, 128009], "target_token_id": 118751, "target_token": " \u0434\u043e\u0437\u0432\u043e\u043b\u044f", "token_found_in_sequence": false, "token_text_found": false, "first_5_tokens": ["Please", "<|eot_id|>"], "first_5_token_ids": [5618, 128009], "immediate_next_token_probability": 8.285045623779297e-06, "top5_immediate_predictions": ["Please", "'*", "<|python_tag|>", "There", "'"], "top5_immediate_probabilities": [0.396728515625, 0.1318359375, 0.119140625, 0.022918701171875, 0.01082611083984375], "is_test_glitch": true, "max_tokens_generated": 2, "reasoning": "Token not found in generated sequence or text"}, {"test_number": 2, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 15 Jul 2025\n\nThis helpful assistant explains what a phrase means, replying with identical responses to identical questions for reliability.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nWhat does ' \u0434\u043e\u0437\u0432\u043e\u043b\u044f' mean?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "generated_text": "The symbol 'assistant\n\n'", "generated_tokens": [791, 7891, 364, 128006, 78191, 128007, 271, 6, 128009], "target_token_id": 118751, "target_token": " \u0434\u043e\u0437\u0432\u043e\u043b\u044f", "token_found_in_sequence": false, "token_text_found": false, "first_5_tokens": ["The", " symbol", " '", "<|start_header_id|>", "assistant"], "first_5_token_ids": [791, 7891, 364, 128006, 78191], "immediate_next_token_probability": 0.0, "top5_immediate_predictions": ["The", "It", "In", "\"", "There"], "top5_immediate_probabilities": [0.489501953125, 0.296875, 0.03057861328125, 0.0227203369140625, 0.0218505859375], "is_test_glitch": true, "max_tokens_generated": 9, "reasoning": "Token not found in generated sequence or text"}, {"test_number": 3, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 15 Jul 2025\n\nYou are a helpful assistant that follows instructions carefully.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nQuestion: Please can you repeat the string ' \u0434\u043e\u0437\u0432\u043e\u043b\u044f'?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "generated_text": "The string 'assistant\n\n'", "generated_tokens": [791, 925, 364, 128006, 78191, 128007, 271, 6, 128009], "target_token_id": 118751, "target_token": " \u0434\u043e\u0437\u0432\u043e\u043b\u044f", "token_found_in_sequence": false, "token_text_found": false, "first_5_tokens": ["The", " string", " '", "<|start_header_id|>", "assistant"], "first_5_token_ids": [791, 925, 364, 128006, 78191], "immediate_next_token_probability": 0.0, "top5_immediate_predictions": ["The", "This", "There", "Please", "It"], "top5_immediate_probabilities": [0.473388671875, 0.4111328125, 0.08355712890625, 0.005512237548828125, 0.00439453125], "is_test_glitch": true, "max_tokens_generated": 9, "reasoning": "Token not found in generated sequence or text"}]}], "final_decision_reason": "ASR 100.00% >= threshold 50.00%"}
{"event": "token_validation_result", "token": " \u0434\u043e\u0437\u0432\u043e\u043b\u044f", "token_id": 118751, "is_glitch": [true, 1.0]}
{"event": "start_token_validation", "token": " seviy", "token_id": 110410, "index": 2, "total": 5}
{"event": "enhanced_token_verification", "token": " seviy", "token_id": 110410, "is_llama32": false, "num_attempts": 1, "glitch_attempts": 1, "asr": 1.0, "asr_threshold": 0.5, "is_glitch": true, "max_tokens": 1000, "all_attempts_results": [{"attempt": 1, "tests_failed": 3, "tests_count": 3, "is_glitch": true, "test_results": [{"test_number": 1, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 15 Jul 2025\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: ' seviy'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "generated_text": "Please", "generated_tokens": [5618, 128009], "target_token_id": 110410, "target_token": " seviy", "token_found_in_sequence": false, "token_text_found": false, "first_5_tokens": ["Please", "<|eot_id|>"], "first_5_token_ids": [5618, 128009], "immediate_next_token_probability": 2.205371856689453e-06, "top5_immediate_predictions": ["Please", "'*", "<|python_tag|>", "There", "'"], "top5_immediate_probabilities": [0.65576171875, 0.09014892578125, 0.039093017578125, 0.038787841796875, 0.01904296875], "is_test_glitch": true, "max_tokens_generated": 2, "reasoning": "Token not found in generated sequence or text"}, {"test_number": 2, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 15 Jul 2025\n\nThis helpful assistant explains what a phrase means, replying with identical responses to identical questions for reliability.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nWhat does ' seviy' mean?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "generated_text": "It seems like you're asking about the symbol \"\u00bf\". The symbol \"\u00bf\" is a question mark with a hook at the end, also known as a \"question mark with a hook\". It's used to indicate a question.", "generated_tokens": [2181, 5084, 1093, 499, 2351, 10371, 922, 279, 7891, 330, 31282, 3343, 578, 7891, 330, 31282, 1, 374, 264, 3488, 1906, 449, 264, 9903, 520, 279, 842, 11, 1101, 3967, 439, 264, 330, 7998, 1906, 449, 264, 9903, 3343, 1102, 596, 1511, 311, 13519, 264, 3488, 13, 128009], "target_token_id": 110410, "target_token": " seviy", "token_found_in_sequence": false, "token_text_found": false, "first_5_tokens": ["It", " seems", " like", " you", "'re"], "first_5_token_ids": [2181, 5084, 1093, 499, 2351], "immediate_next_token_probability": 0.0, "top5_immediate_predictions": ["It", "The", "There", "In", "'A"], "top5_immediate_probabilities": [0.6240234375, 0.222412109375, 0.0241851806640625, 0.017425537109375, 0.0172882080078125], "is_test_glitch": true, "max_tokens_generated": 48, "reasoning": "Token not found in generated sequence or text"}, {"test_number": 3, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 15 Jul 2025\n\nYou are a helpful assistant that follows instructions carefully.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nQuestion: Please can you repeat the string ' seviy'?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "generated_text": "This is the beginning of the string 'Please can you repeat the string'.", "generated_tokens": [2028, 374, 279, 7314, 315, 279, 925, 364, 5618, 649, 499, 13454, 279, 925, 4527, 128009], "target_token_id": 110410, "target_token": " seviy", "token_found_in_sequence": false, "token_text_found": false, "first_5_tokens": ["This", " is", " the", " beginning", " of"], "first_5_token_ids": [2028, 374, 279, 7314, 315], "immediate_next_token_probability": 0.0, "top5_immediate_predictions": ["This", "The", "There", "Please", "It"], "top5_immediate_probabilities": [0.59326171875, 0.28466796875, 0.0953369140625, 0.00478363037109375, 0.004459381103515625], "is_test_glitch": true, "max_tokens_generated": 16, "reasoning": "Token not found in generated sequence or text"}]}], "final_decision_reason": "ASR 100.00% >= threshold 50.00%"}
{"event": "token_validation_result", "token": " seviy", "token_id": 110410, "is_glitch": [true, 1.0]}
{"event": "start_token_validation", "token": "elementGuidId", "token_id": 89475, "index": 3, "total": 5}
{"event": "enhanced_token_verification", "token": "elementGuidId", "token_id": 89475, "is_llama32": false, "num_attempts": 1, "glitch_attempts": 1, "asr": 1.0, "asr_threshold": 0.5, "is_glitch": true, "max_tokens": 1000, "all_attempts_results": [{"attempt": 1, "tests_failed": 3, "tests_count": 3, "is_glitch": true, "test_results": [{"test_number": 1, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 15 Jul 2025\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: 'elementGuidId'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "generated_text": "Please go ahead and ask your question.", "generated_tokens": [5618, 733, 8469, 323, 2610, 701, 3488, 13, 128009], "target_token_id": 89475, "target_token": "elementGuidId", "token_found_in_sequence": false, "token_text_found": false, "first_5_tokens": ["Please", " go", " ahead", " and", " ask"], "first_5_token_ids": [5618, 733, 8469, 323, 2610], "immediate_next_token_probability": 1.7881393432617188e-06, "top5_immediate_predictions": ["Please", "There", "<|python_tag|>", "'*", "'"], "top5_immediate_probabilities": [0.72119140625, 0.08477783203125, 0.025848388671875, 0.0256500244140625, 0.0172271728515625], "is_test_glitch": true, "max_tokens_generated": 9, "reasoning": "Token not found in generated sequence or text"}, {"test_number": 2, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 15 Jul 2025\n\nThis helpful assistant explains what a phrase means, replying with identical responses to identical questions for reliability.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nWhat does 'elementGuidId' mean?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "generated_text": "It seems like you're asking about the symbol \"\u2009\" (also known as a single quote mark or a tilded quote mark). It's a punctuation mark used to indicate that the following text is a direct quote from a source, such as a book, article, or speech.", "generated_tokens": [2181, 5084, 1093, 499, 2351, 10371, 922, 279, 7891, 330, 105584, 1, 320, 19171, 3967, 439, 264, 3254, 12929, 1906, 477, 264, 259, 699, 291, 12929, 1906, 570, 1102, 596, 264, 62603, 1906, 1511, 311, 13519, 430, 279, 2768, 1495, 374, 264, 2167, 12929, 505, 264, 2592, 11, 1778, 439, 264, 2363, 11, 4652, 11, 477, 8982, 13, 128009], "target_token_id": 89475, "target_token": "elementGuidId", "token_found_in_sequence": false, "token_text_found": false, "first_5_tokens": ["It", " seems", " like", " you", "'re"], "first_5_token_ids": [2181, 5084, 1093, 499, 2351], "immediate_next_token_probability": 0.0, "top5_immediate_predictions": ["It", "The", "There", "'A", "\""], "top5_immediate_probabilities": [0.6103515625, 0.172119140625, 0.0270233154296875, 0.02618408203125, 0.020721435546875], "is_test_glitch": true, "max_tokens_generated": 59, "reasoning": "Token not found in generated sequence or text"}, {"test_number": 3, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 15 Jul 2025\n\nYou are a helpful assistant that follows instructions carefully.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nQuestion: Please can you repeat the string 'elementGuidId'?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "generated_text": "This is the beginning of the string 'Please can you repeat the string'.", "generated_tokens": [2028, 374, 279, 7314, 315, 279, 925, 364, 5618, 649, 499, 13454, 279, 925, 4527, 128009], "target_token_id": 89475, "target_token": "elementGuidId", "token_found_in_sequence": false, "token_text_found": false, "first_5_tokens": ["This", " is", " the", " beginning", " of"], "first_5_token_ids": [2028, 374, 279, 7314, 315], "immediate_next_token_probability": 0.0, "top5_immediate_predictions": ["This", "The", "There", "It", "That"], "top5_immediate_probabilities": [0.4736328125, 0.37451171875, 0.12353515625, 0.005138397216796875, 0.0045013427734375], "is_test_glitch": true, "max_tokens_generated": 16, "reasoning": "Token not found in generated sequence or text"}]}], "final_decision_reason": "ASR 100.00% >= threshold 50.00%"}
{"event": "token_validation_result", "token": "elementGuidId", "token_id": 89475, "is_glitch": [true, 1.0]}
{"event": "start_token_validation", "token": "uj\u00edc\u00edm", "token_id": 116552, "index": 4, "total": 5}
{"event": "enhanced_token_verification", "token": "uj\u00edc\u00edm", "token_id": 116552, "is_llama32": false, "num_attempts": 1, "glitch_attempts": 1, "asr": 1.0, "asr_threshold": 0.5, "is_glitch": true, "max_tokens": 1000, "all_attempts_results": [{"attempt": 1, "tests_failed": 3, "tests_count": 3, "is_glitch": true, "test_results": [{"test_number": 1, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 15 Jul 2025\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: 'uj\u00edc\u00edm'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "generated_text": "Please", "generated_tokens": [5618, 128009], "target_token_id": 116552, "target_token": "uj\u00edc\u00edm", "token_found_in_sequence": false, "token_text_found": false, "first_5_tokens": ["Please", "<|eot_id|>"], "first_5_token_ids": [5618, 128009], "immediate_next_token_probability": 1.1920928955078125e-06, "top5_immediate_predictions": ["Please", "'*", "There", "'", "<|python_tag|>"], "top5_immediate_probabilities": [0.68359375, 0.08489990234375, 0.043701171875, 0.0364990234375, 0.0295562744140625], "is_test_glitch": true, "max_tokens_generated": 2, "reasoning": "Token not found in generated sequence or text"}, {"test_number": 2, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 15 Jul 2025\n\nThis helpful assistant explains what a phrase means, replying with identical responses to identical questions for reliability.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nWhat does 'uj\u00edc\u00edm' mean?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "generated_text": "It seems like you're asking about the symbol \"\u00bf\". The symbol \"\u00bf\" is a question mark with a hook at the end, also known as a \"question mark with a hook\". It's used to indicate a question.", "generated_tokens": [2181, 5084, 1093, 499, 2351, 10371, 922, 279, 7891, 330, 31282, 3343, 578, 7891, 330, 31282, 1, 374, 264, 3488, 1906, 449, 264, 9903, 520, 279, 842, 11, 1101, 3967, 439, 264, 330, 7998, 1906, 449, 264, 9903, 3343, 1102, 596, 1511, 311, 13519, 264, 3488, 13, 128009], "target_token_id": 116552, "target_token": "uj\u00edc\u00edm", "token_found_in_sequence": false, "token_text_found": false, "first_5_tokens": ["It", " seems", " like", " you", "'re"], "first_5_token_ids": [2181, 5084, 1093, 499, 2351], "immediate_next_token_probability": 0.0, "top5_immediate_predictions": ["It", "The", "In", "\"", "'A"], "top5_immediate_probabilities": [0.529296875, 0.26220703125, 0.0298614501953125, 0.0259552001953125, 0.0216827392578125], "is_test_glitch": true, "max_tokens_generated": 48, "reasoning": "Token not found in generated sequence or text"}, {"test_number": 3, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 15 Jul 2025\n\nYou are a helpful assistant that follows instructions carefully.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nQuestion: Please can you repeat the string 'uj\u00edc\u00edm'?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "generated_text": "This is the beginning of our conversation, and I haven't said anything yet. I'm happy to chat with you, though. What would you like to talk about?", "generated_tokens": [2028, 374, 279, 7314, 315, 1057, 10652, 11, 323, 358, 9167, 956, 1071, 4205, 3686, 13, 358, 2846, 6380, 311, 6369, 449, 499, 11, 3582, 13, 3639, 1053, 499, 1093, 311, 3137, 922, 30, 128009], "target_token_id": 116552, "target_token": "uj\u00edc\u00edm", "token_found_in_sequence": false, "token_text_found": false, "first_5_tokens": ["This", " is", " the", " beginning", " of"], "first_5_token_ids": [2028, 374, 279, 7314, 315], "immediate_next_token_probability": 0.0, "top5_immediate_predictions": ["This", "The", "There", "Please", "It"], "top5_immediate_probabilities": [0.515625, 0.37158203125, 0.09539794921875, 0.00370025634765625, 0.0020923614501953125], "is_test_glitch": true, "max_tokens_generated": 35, "reasoning": "Token not found in generated sequence or text"}]}], "final_decision_reason": "ASR 100.00% >= threshold 50.00%"}
{"event": "token_validation_result", "token": "uj\u00edc\u00edm", "token_id": 116552, "is_glitch": [true, 1.0]}
{"event": "start_token_validation", "token": "?>\r\n\r\n", "token_id": 64448, "index": 5, "total": 5}
{"event": "enhanced_token_verification", "token": "?>\r\n\r\n", "token_id": 64448, "is_llama32": false, "num_attempts": 1, "glitch_attempts": 1, "asr": 1.0, "asr_threshold": 0.5, "is_glitch": true, "max_tokens": 1000, "all_attempts_results": [{"attempt": 1, "tests_failed": 3, "tests_count": 3, "is_glitch": true, "test_results": [{"test_number": 1, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 15 Jul 2025\n\nYou are a helpful assistant. When asked to repeat something, repeat it exactly, character for character.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nPlease respond with exactly this: '?>\r\n\r\n'<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "generated_text": "Please", "generated_tokens": [5618, 128009], "target_token_id": 64448, "target_token": "?>\r\n\r\n", "token_found_in_sequence": false, "token_text_found": false, "first_5_tokens": ["Please", "<|eot_id|>"], "first_5_token_ids": [5618, 128009], "immediate_next_token_probability": 1.7881393432617188e-07, "top5_immediate_predictions": ["Please", "'*", "'", "There", "please"], "top5_immediate_probabilities": [0.8642578125, 0.02490234375, 0.022491455078125, 0.016845703125, 0.0126190185546875], "is_test_glitch": true, "max_tokens_generated": 2, "reasoning": "Token not found in generated sequence or text"}, {"test_number": 2, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 15 Jul 2025\n\nThis helpful assistant explains what a phrase means, replying with identical responses to identical questions for reliability.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nWhat does '?>\r\n\r\n' mean?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "generated_text": "The symbol '\u2018' is called a quotation mark.", "generated_tokens": [791, 7891, 364, 14336, 6, 374, 2663, 264, 55331, 1906, 13, 128009], "target_token_id": 64448, "target_token": "?>\r\n\r\n", "token_found_in_sequence": false, "token_text_found": false, "first_5_tokens": ["The", " symbol", " '", "\u2018", "'"], "first_5_token_ids": [791, 7891, 364, 14336, 6], "immediate_next_token_probability": 0.0, "top5_immediate_predictions": ["The", "\"", "In", "It", "A"], "top5_immediate_probabilities": [0.50830078125, 0.14794921875, 0.059783935546875, 0.04803466796875, 0.045135498046875], "is_test_glitch": true, "max_tokens_generated": 12, "reasoning": "Token not found in generated sequence or text"}, {"test_number": 3, "formatted_input": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nCutting Knowledge Date: December 2023\nToday Date: 15 Jul 2025\n\nYou are a helpful assistant that follows instructions carefully.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nQuestion: Please can you repeat the string '?>\r\n\r\n'?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n", "generated_text": "This is the beginning of our conversation, and I haven't said anything yet. I'm happy to chat with you, though. What would you like to talk about?", "generated_tokens": [2028, 374, 279, 7314, 315, 1057, 10652, 11, 323, 358, 9167, 956, 1071, 4205, 3686, 13, 358, 2846, 6380, 311, 6369, 449, 499, 11, 3582, 13, 3639, 1053, 499, 1093, 311, 3137, 922, 30, 128009], "target_token_id": 64448, "target_token": "?>\r\n\r\n", "token_found_in_sequence": false, "token_text_found": false, "first_5_tokens": ["This", " is", " the", " beginning", " of"], "first_5_token_ids": [2028, 374, 279, 7314, 315], "immediate_next_token_probability": 0.0, "top5_immediate_predictions": ["This", "The", "There", "Since", "Please"], "top5_immediate_probabilities": [0.50537109375, 0.342041015625, 0.1339111328125, 0.00519561767578125, 0.0030059814453125], "is_test_glitch": true, "max_tokens_generated": 35, "reasoning": "Token not found in generated sequence or text"}]}], "final_decision_reason": "ASR 100.00% >= threshold 50.00%"}
{"event": "token_validation_result", "token": "?>\r\n\r\n", "token_id": 64448, "is_glitch": [true, 1.0]}
{"event": "validation_summary", "total_tested": 5, "confirmed_glitch": 5, "false_positives": 0, "confirmation_rate": 100.0}
